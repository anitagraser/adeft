{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Adeft Models\n",
    "\n",
    "In the [Introduction](introduction.ipynb) notebook, we went over how to use Adeft's pretrained disambiguation models. This notebook is for users who would like to build their own models or simply to better understand the inner workings of adeft. We will go through the steps of creating a model for the shortform IR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining longform expansions from text corpora\n",
    "\n",
    "The first step in building a model is assembling a corpus of texts containing mentions of the desired shortform. Adeft does not provide tools for text acquisition. We assume users will be able to supply their own texts. For the pretrained models, texts are extracted from the [INDRA Database](https://github.com/indralab/indra_db) which is not publically available. We have built the [Adeft App](https://github.com/indralab/adeft_app) based on adeft to build models based on content from the INDRA database. The Adeft App is open source and users are encouraged to look over it for inspiration or fork and modify it for their own purposes. For this tutorial we will use a sample of 500 texts from the over 10,000 texts used to build the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/example_texts.json') as f:\n",
    "    ir_texts = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adeft uses an implementation of the [Acromine](http://www.chokkan.org/research/acromine/) algorithm developed by [NaCTeM](http://www.nactem.ac.uk/index.php) to identify longform expansions for a given shortform within a corpus of texts. This is done by searching for defining patterns (DPs) for the shortform within the texts. Statistical co-occurence frequencies are used to identify the correct expansions corresponding to the defining patterns. Possible expansions for DPs in the sentence before last are\n",
    "* patterns\n",
    "* defining patterns\n",
    "* for defining patterns\n",
    "* searching for defining patterns\n",
    "* etc...\n",
    "\n",
    "A machine cannot apriori tell what the correct expansion is from a single sentence, but by looking at many DPs for DPs within an appropriate corpus of texts it would be able to tell that ***defining patterns*** occurs much more frequently than ***for defining patterns*** and that ***patterns*** occurs rarely without ***defining*** preceding it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Longform expansions can be minded from texts with the AdeftMiner object. The following cell shows how to initialize an AdeftMiner for a given shortform and process a list of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adeft.discover import AdeftMiner\n",
    "\n",
    "ir_miner = AdeftMiner('IR')\n",
    "ir_miner.process_texts(ir_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A score will be produced for each possible longform expansion. Top scoring expansions can be inspected as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_miner.top(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the top scoring expansions do not immediately give the correct expansions. A method is implemented to extract the best potential longforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ir_miner.get_longforms(cutoff=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the method has done a good job of identifying correct longform expansions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build models, users must produce a dictionary mapping longforms to desired grounding labels. We call these grounding maps. For the pretrained models we use labels consisting of a [Name Space](introduction.ipynb#Name-Spaces) and corresponding ID separated by a colon. An example grounding map is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_map = {'ionizing radiation': 'MESH:D011839',\n",
    "                 'insulin resistance': 'MESH:D007333',\n",
    "                 'ischemia reperfusion': 'MESH:D015427',\n",
    "                 'insulin receptor': 'HGNC:6091',\n",
    "                 'irradiation': 'MESH:D011839',\n",
    "                 'infrared': 'MESH:D007259',\n",
    "                 'immunoreactive': 'ungrounded'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adeft is then able to automatically produce labels for some of the texts by searching for defining patterns matching one of these longform expansions. This is done with an AdeftLabeler object. To initialize this object, we need a dictionary mapping shortforms to grounding maps as created above. Dictionaries containing grounding maps for multiple shortforms may be used to produce models for multiple synonymous shortforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_dict = {'IR': grounding_map}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AdeftLabeler is then initialized as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adeft.modeling.label import AdeftLabeler\n",
    "\n",
    "labeler = AdeftLabeler(grounding_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell illustrates how to use the AdeftLabeler. It returns a list of two element tuples. Each tuple contains a text as its first element and a label as its second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = labeler.build_from_texts(ir_texts)\n",
    "texts, labels = zip(*corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output, corpus, contains a list of tuples of which the first element is a text and the second element is a label taken from the values of a grounding map. We use a list unpacking trick with zip to convert this to two lists, a list of texts and a list of labels. Of the 500 input texts, 340 contained defining patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Predictive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An AdeftClassifier can than be used to train a logistic regression model to disambiguate texts that do not contain a defining pattern. The AdeftClassifier must be initialized with the shortform of interest and a list of the labels to consider as positive labels. Users can also pass a list of shortforms for models disambiguating multiple synonymous shortforms. The following cell illustrates the initialization of an AdeftClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from adeft.modeling.classify import AdeftClassifier\n",
    "\n",
    "classifier = AdeftClassifier('IR', ['MESH:D011839', 'HGNC:6091'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Details\n",
    "\n",
    "The AdeftClassifier uses a Logistic Regression model with [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) vectorized [n-gram](https://en.wikipedia.org/wiki/N-gram) features. It is implemented with the [Scikit-Learn](https://scikit-learn.org/stable/) python library. It has three parameters that can be tuned\n",
    "\n",
    "* **C : float**\n",
    "\n",
    "$L_1$ regularization parameter. Following Scikit-learn's Logistic Regression implementation, $C$ is the reciprocal of the $L_1$ penalty $\\lambda$. Lower values of $C$ correspond to greater regularization. $L_1$ Regularization controls model complexity by adding a multiple, $\\lambda$, of the sum of the absolute value of coefficients to the Logistic Regression objective function. *$L_1$ regularization shrinks regression coefficients to zero, with higher regularization causing the model to use fewer features.*\n",
    "\n",
    "* **max_features : int**\n",
    "\n",
    "Cutoff for the number of TF-IDF vectorized n_grams to use as features. Selects the top $n$-grams by frequency in the training set.\n",
    "\n",
    "* **ngram_range : tuple of int**\n",
    "\n",
    "Range of values $n$ for which model takes $n$-grams as features. When ngram_range is set to (1, 1) only unigrams are used. Must be a tuple of ints $(a, b)$ with $a < b$. For ngram_range $(a, b)$ with $a <= b$, a-grams through b-grams are used.\n",
    "\n",
    "### Training\n",
    "The AdeftClassifier has a cv method which can be used to perform a crossvalidated gridsearch and calculate classification metrics for a variety of parameters. We have declared that MESH:D011839 (Ionizing Radiation) and HGNC:6091 (Insulin Receptor) are to be considered as positive labels. This impacts how the classification metrics are calculated. Adeft will report the crossvalidated precision, recall, and F1 score. For multilabel classification, Adeft will take the weighted average of these scores over all positive labels, weighted by the frequency of each label in the test data. The cv method takes a param_grid as used in Sci-kit Learn's [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). This is a dict mapping feature names to lists of values. Crossvalidation is performed for each combination of parameters from the lists.\n",
    "\n",
    "Training with crossvalidation is illustrated in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [10.0], 'max_features': [1000], 'ngram_range': [(1, 2)]}\n",
    "classifier.cv(texts, labels, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter cv can either be an int specifying the number of folds, or a crossvalidation generator or iterable as taken for the cv argument of a  [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) object. A summary of model statistics for the best combination of parameters can be accessed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to access the underlying GridSearchCV object to get more detailed information. See the Scikit-learn documentation for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = classifier.grid_search\n",
    "print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disambiguators\n",
    "\n",
    "We can use the grounding_dict and classifier we've produced to build a disambiguator like the one seen in the [Introduction](introduction.ipynb) notebook. These are instantiated as AdeftDisambiguator objects. An AdeftDisambiguator first seeks to disambiguate text by searching for defining patterns. The logistic regression model is used if a defining pattern is not found.\n",
    "\n",
    "You may recall from the introduction that a disambiguator returns standardized names for each grounding label. These must be explicitly supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {'MESH:D011839': 'Radiation, Ionizing',\n",
    "         'MESH:D007333': 'Insulin Resistance',\n",
    "         'HGNC:6091': 'INSR',\n",
    "         'MESH:D015427': 'Reperfusion Injury',\n",
    "         'MESH:D007259': 'Infrared Rays'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An AdeftDisambiguator is instantiated with a classifier, grounding_dict, and dictionary of names as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adeft.disambiguate import AdeftDisambiguator\n",
    "\n",
    "my_disambiguator = AdeftDisambiguator(classifier, grounding_dict, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may use the info method to see statistics for our custom trained disambiguator just as we could for the pretrained disambiguators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_disambiguator.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then disambiguate the examples from the Introduction notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = ('Ionizing radiation (IR) is radiation that carries enough energy to detach electrons'\n",
    "            ' from atoms or molecules')\n",
    "example2 = ('The detrimental effects of IR involve a highly orchestrated series of'\n",
    "            ' events that are amplified by endogenous signaling and culminating in'\n",
    "            ' oxidative damage to DNA, lipids, proteins, and many metabolites.')\n",
    "with open('data/example.txt') as f:\n",
    "    example3 = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first example contains a defining pattern. The logistic regression classifier is used for the second two examples and produces the correct groundings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_disambiguator.disambiguate(example1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_disambiguator.disambiguate(example2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_disambiguator.disambiguate(example3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Disambiguators\n",
    "\n",
    "Disambiguators can be serialized for use at a later time. A disambiguator has three components, a logistic regression model, a grounding dictionary, and a names dictionary. These will be saved to three separate files within a directory with the following structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `<ModelName>`\n",
    "    - `<ModelName>_grounding_dict.json`\n",
    "    - `<ModelName>_names.json`\n",
    "    - `<ModelName>_model.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_disambiguator.dump('IR', path='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file IR_model.gz contains the coefficients of the logistic regression model, features along with their document frequencies in the training data, and other classifier metadata. These are stored within a json file which is then compressed with gzip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lah 'data/IR/IR_model.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adeft's pretrained models are stored in this format within a hidden folder in the users home directory called .adeft_models. The load_disambiguator function used in the Introduction notebook takes as optional argument a path to the folder where it should look for models. User created models can be loaded in this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adeft.disambiguate import load_disambiguator\n",
    "\n",
    "also_my_disambiguator = load_disambiguator('IR', path='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You simply pass the path to the folder the model where the model is contained. The default value for models_path is ```$HOME/.adeft_models```. Here we've placed the model folder for a model named IR in the data directory for this notebook. Models are stored in folders on the users system keyed by folder name. This introduces some subtleties. Some characters such as \"/\" are not allowed in filenames. Some file systems are not case sensitive. For the pretrained models, we use escape characters to handle these issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(also_my_disambiguator.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the serialized model we have loaded produces the same disambiguation results as the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "also_my_disambiguator.disambiguate(example3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_disambiguator.disambiguate(example3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adeft Grounding Assistant\n",
    "\n",
    "At this time, the tasks of providing groundings for longforms cannot be automated. Adeft provides a simple GUI to assist in the necessary data entry for the grounding process.\n",
    "\n",
    "A function ground_with_gui is provided. It will open a simple web application in the users browser where users can enter groundings for longforms, standardized names, and choose which labels should be considered positive labels when evaluating classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adeft.gui import ground_with_gui\n",
    "\n",
    "\n",
    "longforms, scores = zip(*ir_miner.get_longforms(cutoff=5))\n",
    "result = ground_with_gui(longforms, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A screenshot of the app after all groundings have been entered is shown below. Users can enter names and groundings in the text boxes and then check off the boxes next to the longforms. Clicking submit will gives the checked off longforms the entered name and grounding. Names and groundings can be deleted by pressing the X button to the right of the grounding column. The labels column on the far right is populated with the unique groundings. Clicking the + button toggles whether a lable is considered positive. When the user presses generate, the ground_with_gui function returns a tuple containing a grounding map, a names dictionary, and a list of positive labels. The web application will then stop running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/adeft_app.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users may supply an initial grounding map. When building adeft models, we supply initial grounding maps generating by an imperfect grounding function and then use the GUI to manually review and correct these initial groundings. If a grounding map is supplied, an initial names map and list of positive labels can also be supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = ground_with_gui(longforms, scores, grounding_map=grounding_map, names_map=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "If you've followed along with this notebook, you're ready to build your own disambiguation models provided that you have access to proper text corpora. If you believe you've found a bug in Adeft please submit an issue at https://github.com/indralab/adeft/issues. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

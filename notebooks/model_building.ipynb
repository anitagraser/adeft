{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Adeft Models\n",
    "\n",
    "The [Introduction](introduction.ipynb) notebook explains how to use Adeft's pretrained disambiguation models. This notebook is for users who would like to build their own models or simply to better understand the inner workings of Adeft. Here we will go through the steps of creating a model for the shortform `IR`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining longform expansions from text corpora\n",
    "\n",
    "The first step in building a model is assembling a corpus of texts containing mentions of the desired shortform. Adeft does not provide tools for text acquisition. We assume users will be able to supply their own texts. For the pretrained models, texts are extracted from the [INDRA Database](https://github.com/indralab/indra_db) (which is not publicly available). For this tutorial we will use a sample of 500 texts from the over 10,000 texts used to build the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/example_texts.json') as f:\n",
    "    ir_texts = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adeft uses an implementation of the [Acromine](http://www.chokkan.org/research/acromine/) algorithm developed by [NaCTeM](http://www.nactem.ac.uk/software/acromine/) to identify longform expansions for a given shortform within a corpus of texts. This is done by searching for defining patterns (DPs) for the shortform within the texts. Statistical co-occurence frequencies are used to identify the correct expansions corresponding to the defining patterns. For example in the phrase\n",
    "\n",
    "> This is done by searching for defining patterns (DPs)...\n",
    "\n",
    "possible expansions for `DPs`, based on the text preceding the parentheses, are:\n",
    "* `patterns`\n",
    "* `defining patterns`\n",
    "* `for defining patterns`\n",
    "* `searching for defining patterns`\n",
    "* etc...\n",
    "\n",
    "While the appropriate text boundaries for the longform is difficult to determine from a single sentence, the\n",
    "correct scope can be determined looking at defining patterns in a large corpus of texts. For example, given many such texts, the Acromine algorithm can determine that `defining patterns` occurs much more frequently than `for defining patterns` and that `patterns` occurs rarely without `defining` preceding it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Longform expansions are mined from texts with the ``AdeftMiner`` class. The following code shows how to initialize an instance of ``AdeftMiner`` for a given shortform and process a list of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adeft.discover import AdeftMiner\n",
    "\n",
    "ir_miner = AdeftMiner('IR')\n",
    "ir_miner.process_texts(ir_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A score will be produced for each possible longform expansion. Top scoring expansions can be inspected as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_miner.top(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A score will be produced for each possible longform expansion. Top scoring expansions can be inspected as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ir_miner.top(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These \"raw\" longforms include redundant/overlapping entries (for example, \"ionizing radiation\" and \"to ionizing radiation\", and \"insulin resistance\" and \"of insulin resistance\"). Adeft analyzes the words in each longform to identify and remove non-relevant prefixes, arriving at an optimized set which can be inspected using the method ``get_longforms``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_miner.get_longforms(cutoff=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, for Adeft obtains a good set of longforms for ``IR`` from this corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling Texts\n",
    "\n",
    "To build models, users must produce a dictionary that maps longforms to desired identifiers. We call these *grounding maps*. For the pretrained models we use labels consisting of a [Namespace](introduction.ipynb#Name-Spaces) and corresponding ID separated by a colon. An example grounding map is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_map = {'ionizing radiation': 'MESH:D011839',\n",
    "                 'insulin resistance': 'MESH:D007333',\n",
    "                 'ischemia reperfusion': 'MESH:D015427',\n",
    "                 'insulin receptor': 'HGNC:6091',\n",
    "                 'irradiation': 'MESH:D011839',\n",
    "                 'infrared': 'MESH:D007259',\n",
    "                 'immunoreactive': 'ungrounded'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a grounding map, Adeft can automatically associate identifiers with the texts in the training corpus that contain defining patterns corresponding to one of the longform expansions in the grounding map. This is done with the ``AdeftLabeler`` class. To initialize this object, we need a dictionary mapping each shortform to a grounding map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_dict = {'IR': grounding_map}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, it may be useful to train a model for multiple synonymous shortforms. For example, \"nanoparticles\" can be abbreviated as ``NP`` or ``NPs``, and it is useful to train a single model on texts containing both shortforms. In this case one can create a dictionary linking a grounding map to each shortform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_grounding_dict = {\"NP\":  {\"nanoparticle\": \"MESH:D053758\",\n",
    "                             \"nucleus pulposus\": \"MESH:D000070614\",\n",
    "                             \"nucleoprotein\": \"MESH:D009698\",},\n",
    "                     \"NPs\": {\"nanoparticles\": \"MESH:D053758\",\n",
    "                             \"natriuretic peptides\": \"FPLX:Natriuretic_peptide\",\n",
    "                             \"nurse practitioners\": \"ungrounded\",}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a grounding dictionary for the relevant shortform(s), the ``AdeftLabeler`` is initialized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adeft.modeling.label import AdeftLabeler\n",
    "\n",
    "labeler = AdeftLabeler(grounding_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texts for model training are labeled using the ``AdeftLabeler.build_from_texts`` method. The output, ``corpus``, contains a list of two-element tuples of which the first element is a text and the second element is a label taken from the values of the grounding map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus = labeler.build_from_texts(ir_texts)\n",
    "print(\"corpus[0][0]: %s...\" % corpus[0][0][0:70])\n",
    "print(\"corpus[0][1]: %s\" % str(corpus[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use ``zip`` to convert this to two lists: a list of texts and a corresponding list of labels. Of the 500 input texts, 340 contained defining patterns for ``IR``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = zip(*corpus)\n",
    "\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Predictive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``AdeftClassifier`` class can then be used to train a logistic regression model to disambiguate texts that do not contain a defining pattern. The ``AdeftClassifier`` must be initialized with the shortform of interest and a list of the labels to consider as *positive* labels. A positive label is one that is considered relevant to the user's information extraction task. Precision, recall, and F1 scores are calculated using a weighted average of the positive labels. The following code illustrates the initialization of an ``AdeftClassifier``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from adeft.modeling.classify import AdeftClassifier\n",
    "\n",
    "classifier = AdeftClassifier('IR', ['MESH:D011839', 'HGNC:6091'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training models to disambiguate multiple synonymous shortforms (as in the case  of ``NP``/``NPs``, above), the ``AdeftClassifier`` is passed a list of shortforms, as in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_classifier = AdeftClassifier(['NP', 'NPs'], ['MESH:D053758', 'FPLX:Natriuretic_peptide'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Details\n",
    "\n",
    "The AdeftClassifier uses a Logistic Regression model with [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) vectorized [n-gram](https://en.wikipedia.org/wiki/N-gram) features. It is implemented with the [Scikit-Learn](https://scikit-learn.org/stable/) Python library. It has three parameters that can be tuned:\n",
    "\n",
    "* **C : float**\n",
    "\n",
    "$L_1$ regularization parameter. Following Scikit-learn's Logistic Regression implementation, $C$ is the reciprocal of the $L_1$ penalty $\\lambda$. Lower values of $C$ correspond to greater regularization. $L_1$ Regularization controls model complexity by adding a multiple, $\\lambda$, of the sum of the absolute value of coefficients to the Logistic Regression objective function. *$L_1$ regularization shrinks regression coefficients to zero, with higher regularization causing the model to use fewer features.*\n",
    "\n",
    "* **max_features : int**\n",
    "\n",
    "Cutoff for the number of TF-IDF vectorized $n$-grams to use as features. Selects the top $n$-grams by frequency in the training set.\n",
    "\n",
    "* **ngram_range : tuple of int**\n",
    "\n",
    "Range of values $n$ for which model takes $n$-grams as features. When ngram_range is set to (1, 1) only unigrams are used. Must be a tuple of ints $(a, b)$ with $a < b$. For ngram_range $(a, b)$ with $a <= b$, a-grams through b-grams are used.\n",
    "\n",
    "### Training\n",
    "\n",
    "The ``AdeftClassifier`` has a ``cv`` method which can be used to perform a cross-validated grid search to calculate classification metrics for a variety of parameter values. In this example, we have specified that only ``MESH:D011839`` (Ionizing Radiation) and ``HGNC:6091`` (Insulin Receptor) are to be considered as positive labels. This impacts how the classification metrics are calculated and hence how the training parameters are optimized. ``Adeft`` will report the crossvalidated precision, recall, and F1 score. For multilabel classification, ``Adeft`` will take the average of these scores over all positive labels, weighted by the frequency of each label in the test data. The ``cv`` method takes a ``param_grid`` argument as used in Sci-kit Learn's [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). ``param_grid`` must be provided as a dictionary mapping feature names to lists of values. Crossvalidation is performed for each combination of parameters from the lists.\n",
    "\n",
    "The following illustrates training with cross-validation using two alternative values for ``max_features``, 100 and 1000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [10.0], 'max_features': [100, 1000], 'ngram_range': [(1, 2)]}\n",
    "classifier.cv(texts, labels, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter ``cv`` can either be an ``int`` specifying the number of folds, or a cross-validation generator or iterable as taken for the ``cv`` argument of a  [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) object. A summary of model statistics for the best combination of parameters can be accessed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to access the underlying [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) object to get more detailed information. See the Scikit-learn documentation for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = classifier.grid_search\n",
    "print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disambiguators\n",
    "\n",
    "The logistic regression classifier we've produced in the steps above can be combined with the ``grounding_dict`` to build a disambiguator like the one shown in the [Introduction](introduction.ipynb) notebook. These are instantiated as ``AdeftDisambiguator`` objects. An ``AdeftDisambiguator`` first seeks to disambiguate text by searching for defining patterns. The logistic regression model is used only if a defining pattern for the shortform is not found.\n",
    "\n",
    "You may recall from the introduction that a disambiguator returns standardized names for each grounding label. These must be explicitly supplied, as in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {'MESH:D011839': 'Radiation, Ionizing',\n",
    "         'MESH:D007333': 'Insulin Resistance',\n",
    "         'HGNC:6091': 'INSR',\n",
    "         'MESH:D015427': 'Reperfusion Injury',\n",
    "         'MESH:D007259': 'Infrared Rays'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ``AdeftDisambiguator`` is instantiated with a classifier, grounding_dict, and dictionary of names as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adeft.disambiguate import AdeftDisambiguator\n",
    "\n",
    "my_disambiguator = AdeftDisambiguator(classifier, grounding_dict, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the ``info`` method to see statistics for our custom disambiguator just as for the pretrained disambiguators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_disambiguator.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then disambiguate the examples from the Introduction notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = ('Ionizing radiation (IR) is radiation that carries enough energy to detach electrons'\n",
    "            ' from atoms or molecules')\n",
    "example2 = ('The detrimental effects of IR involve a highly orchestrated series of'\n",
    "            ' events that are amplified by endogenous signaling and culminating in'\n",
    "            ' oxidative damage to DNA, lipids, proteins, and many metabolites.')\n",
    "with open('data/example.txt') as f:\n",
    "    example3 = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first example contains a defining pattern. The logistic regression classifier is used for the second two examples and produces the correct groundings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_disambiguator.disambiguate(example1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_disambiguator.disambiguate(example2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_disambiguator.disambiguate(example3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Disambiguators\n",
    "\n",
    "Disambiguators can be serialized for use at a later time. A disambiguator has three components: a logistic regression model, a grounding dictionary, and a names dictionary. These will be saved to three separate files within a directory with the following structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `<ModelName>`\n",
    "    - `<ModelName>_grounding_dict.json`\n",
    "    - `<ModelName>_names.json`\n",
    "    - `<ModelName>_model.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models are saved to the user's filesystem using ``AdeftDisambiguator.dump``, which takes two arguments: a string identifying the model (e.g., ``IR``), and a path to a folder for storing models. Because the model identifier is used to create subfolders within the model directory, characters such as \"/\" should not be used. Also note that some file systems (e.g., Mac OS) are case-insensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_disambiguator.dump('IR', path='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ``IR`` subfolder is created for the model inside the ``data`` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls -lh 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model folder contains three files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lh 'data/IR/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file ``IR_model.gz`` contains the coefficients of the logistic regression model, the $n$-gram features along with their frequencies in the document training data, and other classifier metadata. These are stored within a json file which is then compressed with gzip. The grounding and names dictionaries are serialized directly to json. When downloaded, ``Adeft``'s pretrained models are stored in this format within a hidden folder in the users home directory called ``.adeft``.\n",
    "\n",
    "To load custom models, the ``load_disambiguator`` function used in the Introduction notebook can be passed an optional ``path`` argument for a user-specified model folder, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adeft.disambiguate import load_disambiguator\n",
    "\n",
    "also_my_disambiguator = load_disambiguator('IR', path='data')\n",
    "\n",
    "print(also_my_disambiguator.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The serialized model we have loaded produces the same disambiguation results as the original model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "also_my_disambiguator.disambiguate(example3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_disambiguator.disambiguate(example3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adeft Grounding Assistant\n",
    "\n",
    "Because the task of linking groundings to longforms is not automated, Adeft provides a simple graphical user interface to assist with data entry for grounding.\n",
    "\n",
    "The function ``adeft.gui.ground_with_gui`` opens a simple web application in the browser to allow users to enter groundings for longforms, standardized names, and choose which labels should be considered positive labels when evaluating classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adeft.gui import ground_with_gui\n",
    "\n",
    "longforms, scores = zip(*ir_miner.get_longforms(cutoff=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ground_with_gui(longforms, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A screenshot of the app after all groundings have been entered is shown below. Users can enter names and groundings in the text boxes and then check off the boxes next to the longforms. Clicking submit will gives the checked off longforms the entered name and grounding. Names and groundings can be deleted by pressing the X button to the right of the grounding column. The labels column on the far right is populated with the unique groundings. Clicking the + button toggles whether a lable is considered positive. When the user presses generate, the ground_with_gui function returns a tuple containing a grounding map, a names dictionary, and a list of positive labels. The web application will then stop running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/adeft_app.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users may supply an initial grounding map. When building adeft models, we supply initial grounding maps generating by an imperfect grounding function and then use the GUI to manually review and correct these initial groundings. If a grounding map is supplied, an initial names map and list of positive labels can also be supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = ground_with_gui(longforms, scores, grounding_map=grounding_map, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Groundings without Retraining\n",
    "\n",
    "It's possible to modify groundings and standardized names without having to retrain the classifier. Suppose for\n",
    "instance that you prefer the Uniprot grounding for Insulin Receptor the the HGNC grounding and the protein name *Insulin Receptor* to the HGNC symbol INSR. This can be accomplished with a disambiguators ```modify_groundings``` method. Users can pass in dictionaries mapping previous groundings to new groundings, and previous groundings to new names. This method does not allow for two distinct groundings to be mapped to the same new grounding. Users should retrain the model if this is desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_disambiguator.modify_groundings(new_groundings={'HGNC:6091': 'UP:P06213'},\n",
    "                                   new_names={'HGNC:6091': 'Insulin Receptor'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see below that the model info has successfully changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_disambiguator.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and disambiguations are now made with the updated grounding and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_disambiguator.disambiguate(example3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "If you've followed along with this notebook, you're ready to build your own disambiguation models provided that you have access to proper text corpora. If you believe you've found a bug in Adeft please submit an issue at https://github.com/indralab/adeft/issues. If you'd like to contribute see https://github.com/indralab/adeft/CONTRIBUTING.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

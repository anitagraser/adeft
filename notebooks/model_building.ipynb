{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Adeft Models\n",
    "\n",
    "In the [introduction](introduction.ipynb) notebook, we went over how to use Adeft's pretrained disambiguation models. This notebook is for users who would like to build their own models or simply to better understand the inner workings of adeft. We will go through the steps of creating a model for the shortform IR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining longform expansions from text corpora\n",
    "\n",
    "The first step in building a model is assembling a corpus of texts containing mentions of the desired shortform. Adeft does not provide tools for text acquisition. We assume users will be able to supply their own texts. For the pretrained models, texts are extracted from the [INDRA Database](https://github.com/indralab/indra_db) which is not publically available. We have built the [Adeft App](https://github.com/indralab/adeft_app) based on adeft to build models based on content from the INDRA database. The Adeft App is open source and users are encouraged to look over it for inspiration or fork and modify it for their own purposes. For this tutorial we will use a sample of 500 texts from the over 10,000 texts used to build the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/example_texts.json') as f:\n",
    "    ir_texts = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adeft uses an implementation of the [Acromine](http://www.chokkan.org/research/acromine/) algorithm developed by [NaCTeM](http://www.nactem.ac.uk/index.php) to identify longform expansions for a given shortform within a corpus of texts. This is done by searching for defining patterns (DPs) for the shortform within the texts. Statistical co-occurence frequencies are used to identify the correct expansions corresponding to the defining patterns. Possible expansions for DPs in the sentence before last are\n",
    "* patterns\n",
    "* defining patterns\n",
    "* for defining patterns\n",
    "* searching for defining patterns\n",
    "* etc...\n",
    "\n",
    "A machine cannot apriori tell what the correct expansion is from a single sentence, but by looking at many DPs within an appropriate corpus of texts it would be able to tell that ***defining patterns*** occurs much more frequently than ***for defining patterns*** and that ***patterns*** occurs rarely without ***defining*** preceding it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Longform expansions can be minded from texts with the AdeftMiner object. The following cell shows how to initialize an AdeftMiner for a given shortform and process a list of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adeft.discover import AdeftMiner\n",
    "\n",
    "ir_miner = AdeftMiner('IR')\n",
    "ir_miner.process_texts(ir_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A score will be produced for each possible longform expansion. Top scoring expansions can be inspected as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ionizing radiation', 132.3956834532374),\n",
       " ('insulin resistance', 125.3089430894309),\n",
       " ('ischemia reperfusion', 73.12328767123287),\n",
       " ('insulin receptor', 69.90697674418604),\n",
       " ('radiation', 48.84269662921349),\n",
       " ('to ionizing radiation', 36.46511627906977),\n",
       " ('the insulin receptor', 30.176470588235293),\n",
       " ('irradiation', 20.782608695652172),\n",
       " ('of insulin resistance', 17.263157894736846),\n",
       " ('reperfusion', 16.813953488372093)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_miner.top(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the top scoring expansions do not immediately give the correct expansions. A method is implemented to extract the best potential longforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ionizing radiation', 132.3956834532374),\n",
       " ('insulin resistance', 125.3089430894309),\n",
       " ('ischemia reperfusion', 73.12328767123287),\n",
       " ('insulin receptor', 69.90697674418604),\n",
       " ('irradiation', 20.782608695652172),\n",
       " ('infrared', 15.777777777777779),\n",
       " ('immunoreactive', 6.0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_miner.get_longforms(cutoff=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the method has done a good job of identifying correct longform expansions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build models, users must produce a dictionary mapping longforms to desired grounding labels. We call these grounding maps. For the pretrained models we use labels consisting of a [Name Space](introduction.ipynb#Name-Spaces) and corresponding ID separated by a colon. In the [Adeft App](https://github.com/indralab/adeft_app) we've implemented a simple GUI to assist in building these dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_map = {'ionizing radiation': 'MESH:D011839',\n",
    "                 'insulin resistance': 'MESH:D007333',\n",
    "                 'ischemia reperfusion': 'MESH:D015427',\n",
    "                 'insulin receptor': 'HGNC:6091',\n",
    "                 'irradiation': 'MESH:D011839',\n",
    "                 'infrared': 'ungrounded',\n",
    "                 'immunoreactive': 'ungrounded'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adeft is then able to automatically produce labels for some of the texts by searching for defining patterns matching one of these longform expansions. This is done with an AdeftLabeler object. To initialize this object, we need a dictionary mapping shortforms to grounding maps as created above. Dictionaries containing grounding maps for multiple shortforms may be used to produce models for multiple synonymous shortforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_dict = {'IR': grounding_map}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AdeftLabeler is then initialized as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adeft.modeling.label import AdeftLabeler\n",
    "\n",
    "labeler = AdeftLabeler(grounding_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell illustrates how to use the AdeftLabeler. It returns a list of two element tuples. Each tuple contains a text as its first element and a label as its second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = labeler.build_from_texts(ir_texts)\n",
    "texts, labels = zip(*corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output, corpus, contains a list of tuples of which the first element is a text and the second element is a label taken from the values of a grounding map. We use a list unpacking trick with zip to convert this to two lists, a list of texts and a list of labels. Of the 500 input texts, 340 contained defining patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Predictive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An AdeftClassifier can than be used to train a logistic regression model to disambiguate texts that do not contain a defining pattern. The AdeftClassifier must be initialized with the shortform of interest and a list of the labels to consider as positive labels. Users can also pass a list of shortforms for models disambiguating multiple synonymous shortforms. The following cell illustrates the initialization of an AdeftClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from adeft.modeling.classify import AdeftClassifier\n",
    "\n",
    "classifier = AdeftClassifier('IR', ['MESH:D011839', 'HGNC:6091'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Details\n",
    "\n",
    "The AdeftClassifier uses a Logistic Regression model with [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) vectorized [n-gram](https://en.wikipedia.org/wiki/N-gram) features. It is implemented with the [Scikit-Learn](https://scikit-learn.org/stable/) python library. It has three parameters that can be tuned\n",
    "\n",
    "* **C : float**\n",
    "\n",
    "$L_1$ regularization parameter. Following Scikit-learn's Logistic Regression implementation, $C$ is the reciprocal of the $L_1$ penalty $\\lambda$. Lower values of $C$ correspond to greater regularization. $L1$ Regularization controls model complexity by adding a multiple, $\\lambda$, of the sum of the absolute value of coefficients to the Logistic Regression objective function. *$L_1$ regularization shrinks regression coefficients to zero, with higher regularization causing the model to use fewer features.*\n",
    "\n",
    "* **max_features : int**\n",
    "\n",
    "Cutoff for the number of TF-IDF vectorized n_grams to use as features. Selects the top $n$-grams by frequency in the training set.\n",
    "\n",
    "* **ngram_range : tuple of int**\n",
    "\n",
    "Range of values $n$ for which model takes $n$-grams as features. When ngram_range is set to (1, 1) only unigrams are used. Must be a tuple of ints $(a, b)$ with $a < b$. For ngram_range $(a, b)$ with $a <= b$, a-grams through b-grams are used.\n",
    "\n",
    "### Training\n",
    "The AdeftClassifier has a cv method which can be used to perform a crossvalidated gridsearch and calculate classification metrics for a variety of parameters. We have declared that MESH:D011839 (Ionizing Radiation) and HGNC:6091 (Insulin Receptor) are to be considered as positive labels. This impacts how the classification metrics are calculated. Adeft will report the crossvalidated precision, recall, and F1 score. For multilabel classification, Adeft will take the weighted average of these scores over all positive labels, weighted by the frequency of each label in the test data. The cv method takes a param_grid as used in Sci-kit Learn's [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). This is a dict mapping feature names to lists of values. Crossvalidation is performed for each combination of parameters from the lists.\n",
    "\n",
    "Training with crossvalidation is illustrated in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [10.0], 'max_features': [1000], 'ngram_range': [(1, 2)]}\n",
    "classifier.cv(texts, labels, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter cv can either be an int specifying the number of folds, or a crossvalidation generator or iterable as taken for the cv argument of a  [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) object. A summary of model statistics for the best combination of parameters can be accessed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_distribution': {'MESH:D007333': 88,\n",
       "  'MESH:D011839': 121,\n",
       "  'HGNC:6091': 70,\n",
       "  'MESH:D015427': 44,\n",
       "  'ungrounded': 17},\n",
       " 'f1': {'mean': 0.9156382549969049, 'std': 0.022090185589664735},\n",
       " 'precision': {'mean': 0.8887090512018272, 'std': 0.023986053595694345},\n",
       " 'recall': {'mean': 0.9477732793522268, 'std': 0.032975453755946946}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to access the underlying GridSearchCV object to get more detailed information. See the Scikit-learn documentation for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([1.05533218]), 'std_fit_time': array([0.01500571]), 'mean_score_time': array([0.30904794]), 'std_score_time': array([0.02238507]), 'param_logit__C': masked_array(data=[10.0],\n",
      "             mask=[False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_tfidf__max_features': masked_array(data=[1000],\n",
      "             mask=[False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_tfidf__ngram_range': masked_array(data=[(1, 2)],\n",
      "             mask=[False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'logit__C': 10.0, 'tfidf__max_features': 1000, 'tfidf__ngram_range': (1, 2)}], 'split0_test_f1': array([0.92011834]), 'split1_test_f1': array([0.93798783]), 'split2_test_f1': array([0.89781103]), 'split3_test_f1': array([0.88319088]), 'split4_test_f1': array([0.93908319]), 'mean_test_f1': array([0.91563825]), 'std_test_f1': array([0.02209019]), 'rank_test_f1': array([1], dtype=int32), 'split0_test_pr': array([0.92260209]), 'split1_test_pr': array([0.90565789]), 'split2_test_pr': array([0.87578947]), 'split3_test_pr': array([0.85309427]), 'split4_test_pr': array([0.88640152]), 'mean_test_pr': array([0.88870905]), 'std_test_pr': array([0.02398605]), 'rank_test_pr': array([1], dtype=int32), 'split0_test_rc': array([0.92307692]), 'split1_test_rc': array([0.97368421]), 'split2_test_rc': array([0.92105263]), 'split3_test_rc': array([0.92105263]), 'split4_test_rc': array([1.]), 'mean_test_rc': array([0.94777328]), 'std_test_rc': array([0.03297545]), 'rank_test_rc': array([1], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "grid_search = classifier.grid_search\n",
    "print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disambiguators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {'MESH:D011839': 'Radiation, Ionizing',\n",
    "         'MESH:D007333': 'Insulin Resistance',\n",
    "         'HGNC:6091': 'INSR',\n",
    "         'MESH:D015427': 'Reperfusion Injury'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adeft.disambiguate import AdeftDisambiguator\n",
    "\n",
    "my_disambiguator = AdeftDisambiguator(classifier, grounding_dict, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disambiguation model for IR\n",
      "\n",
      "Produces the disambiguations:\n",
      "\tRadiation, Ionizing*\tMESH:D011839\n",
      "\tInsulin Resistance\tMESH:D007333\n",
      "\tINSR*\tHGNC:6091\n",
      "\tReperfusion Injury\tMESH:D015427\n",
      "\n",
      "Training data had class balance:\n",
      "\tRadiation, Ionizing*\t121\n",
      "\tInsulin Resistance\t88\n",
      "\tINSR*\t70\n",
      "\tReperfusion Injury\t44\n",
      "\tUngrounded\t17\n",
      "\n",
      "Classification Metrics:\n",
      "\tF1 score:\t0.91564\n",
      "\tPrecision:\t0.88871\n",
      "\tRecall:\t\t0.94777\n",
      "\n",
      "* Positive labels\n",
      "See Docstring for explanation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(my_disambiguator.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "disambs = my_disambiguator.disambiguate(ir_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = ('Ionizing radiation (IR) is radiation that carries enough energy to detach electrons'\n",
    "            ' from atoms or molecules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MESH:D011839',\n",
       " 'Radiation, Ionizing',\n",
       " {'HGNC:6091': 0.0,\n",
       "  'MESH:D007333': 0.0,\n",
       "  'MESH:D011839': 1.0,\n",
       "  'ungrounded': 0.0,\n",
       "  'MESH:D015427': 0.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_disambiguator.disambiguate(example1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2 = 'IR is radiation that carries enough energy to detach electrons from atoms or molecules'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MESH:D011839',\n",
       " 'Radiation, Ionizing',\n",
       " {'HGNC:6091': 0.029510016355119264,\n",
       "  'MESH:D007333': 0.08471306232236007,\n",
       "  'MESH:D011839': 0.6437228878920963,\n",
       "  'MESH:D015427': 0.05812736438929494,\n",
       "  'ungrounded': 0.18392666904112942})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_disambiguator.disambiguate(example2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/example.txt') as f:\n",
    "    example3 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('HGNC:6091',\n",
       " 'INSR',\n",
       " {'HGNC:6091': 0.9806451466133977,\n",
       "  'MESH:D007333': 0.018681316518097377,\n",
       "  'MESH:D011839': 0.00015954836583725616,\n",
       "  'MESH:D015427': 0.00020904676603453542,\n",
       "  'ungrounded': 0.00030494173663304084})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_disambiguator.disambiguate(example3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
